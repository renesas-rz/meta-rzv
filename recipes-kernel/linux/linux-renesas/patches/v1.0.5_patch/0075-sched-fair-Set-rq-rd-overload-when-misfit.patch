From 7b99fd1435e71c1bff65dc1a5483f8ba5206a941 Mon Sep 17 00:00:00 2001
From: Hien Huynh <hien.huynh.px@renesas.com>
Date: Mon, 3 Jun 2019 13:07:12 +0700
Subject: [PATCH 075/458] sched/fair: Set rq->rd->overload when misfit

Idle balance is a great opportunity to pull a misfit task. However,
there are scenarios where misfit tasks are present but idle balance
is prevented by the overload flag.

A good example of this is a workload of n identical tasks. Let's
suppose we have a 2+2 Arm big.LITTLE system. We then spawn 4 fairly
CPU-intensive tasks - for the sake of simplicity let's say they are
just CPU hogs, even when running on big CPUs.

They are identical tasks, so on an SMP system they should all end at
(roughly) the same time. However, in our case the LITTLE CPUs are
less performing than the big CPUs, so tasks running on the LITTLEs will
have a longer completion time.

This means that the big CPUs will complete their work earlier, at
which point they should pull the tasks from the LITTLEs. What we want to
happen is summarized as follows:

a,b,c,d are our CPU-hogging tasks
_ signifies idling

LITTLE_0 | a a a a _ _
LITTLE_1 | b b b b _ _
---------|-------------
big_0  | c c c c a a
big_1  | d d d d b b
                  ^
                  ^
Tasks end on the big CPUs, idle balance happens
and the misfit tasks are pulled straight away

This however won't happen, because currently the overload flag is
only set when there is any CPU that has more than one runnable task -
which may very well not be the case here if our CPU-hogging workload is
all there is to run.

As such, this commit sets the overload flag in update_sg_lb_stats
when a group is flagged as having a misfit task.

Cherry-picked from https://patchwork.kernel.org/patch/10506525/

cc: Ingo Molnar <mingo@redhat.com>
cc: Peter Zijlstra <peterz@infradead.org>

Signed-off-by: Valentin Schneider <valentin.schneider@arm.com>
Signed-off-by: Morten Rasmussen <morten.rasmussen@arm.com>
Signed-off-by: Gaku Inami <gaku.inami.xh@renesas.com>
Signed-off-by: Hien Huynh <hien.huynh.px@renesas.com>
---
 kernel/sched/fair.c  | 6 ++++--
 kernel/sched/sched.h | 6 +++++-
 2 files changed, 9 insertions(+), 3 deletions(-)

diff --git a/kernel/sched/fair.c b/kernel/sched/fair.c
index ad8a864..e0e17cd 100644
--- a/kernel/sched/fair.c
+++ b/kernel/sched/fair.c
@@ -8015,7 +8015,7 @@ static bool update_nohz_stats(struct rq *rq, bool force)
  * @load_idx: Load index of sched_domain of this_cpu for load calc.
  * @local_group: Does group contain this_cpu.
  * @sgs: variable to hold the statistics for this group.
- * @overload: Indicate more than one runnable task for any CPU.
+ * @overload: Indicate pullable load (e.g. >1 runnable task).
  */
 static inline void update_sg_lb_stats(struct lb_env *env,
 			struct sched_group *group, int load_idx,
@@ -8059,8 +8059,10 @@ static inline void update_sg_lb_stats(struct lb_env *env,
 			sgs->idle_cpus++;
 
 		if (env->sd->flags & SD_ASYM_CPUCAPACITY &&
-		sgs->group_misfit_task_load < rq->misfit_task_load)
+		sgs->group_misfit_task_load < rq->misfit_task_load) {
 			sgs->group_misfit_task_load = rq->misfit_task_load;
+			*overload = 1;
+		}
 	}
 
 	/* Adjust by relative CPU capacity of the group */
diff --git a/kernel/sched/sched.h b/kernel/sched/sched.h
index 9d2943b..4ed0490 100644
--- a/kernel/sched/sched.h
+++ b/kernel/sched/sched.h
@@ -720,7 +720,11 @@ struct root_domain {
 	cpumask_var_t		span;
 	cpumask_var_t		online;
 
-	/* Indicate more than one runnable task for any CPU */
+	/*
+	 * Indicate pullable load on at least one CPU, e.g:
+	 * - More than one runnable task
+	 * - Running task is misfit
+	 */
 	int			overload;
 
 	/*
-- 
2.7.4

